# AI_Driven_Harmful_Language_Detector
This project is an AI-powered harmful language detection system that works in two interfaces:

🔹 Chat Interface – A web-based chat system where messages are analyzed for toxicity in real-time.

🔹 Discord Bot – A bot that moderates Discord servers by detecting and handling harmful messages.

At its core, the system uses the Unary Toxic BERT model, a deep learning-based NLP model specialized in detecting harmful and offensive language. The model processes incoming text and classifies it based on toxicity levels. Actions such as flagging, warning, muting, or kicking users are taken based on the detected toxicity score.


Key Features

✅ AI-powered text analysis for harmful content

✅ Chat interface for real-time toxicity monitoring

✅ Discord bot for automatic moderation

✅ Emoji-based filtering for offensive symbols

✅ Automated warnings, muting, and kicking

✅ Deployed using Replit + Uptime bot




⚠️ Important Note
This project includes a list of harmful words and phrases strictly for detection and filtering purposes. These words are not intended for offensive use but are necessary for the AI model to function correctly. Please Ignore.

Link to test Chat Interface : https://ai-harmful-language-frontend.onrender.com/

Link to test Discord Bot : https://discord.gg/qEFhZtf4
