This project is an AI-powered harmful language detection system that works across two interfaces:

🔹 Chat Interface – A web-based chat system where messages are analyzed for toxicity in real-time.

🔹 Discord Bot – A bot that moderates Discord servers by detecting and handling harmful messages.

At its core, the system uses the Unary Toxic BERT model, a deep learning-based NLP model specialized in detecting harmful and offensive language. The model processes incoming text and classifies it based on toxicity levels. Actions such as flagging, warning, muting, or kicking users are taken based on the detected toxicity score.

🚀 Key Features
✅ AI-powered text analysis for harmful content detection

✅ Real-time toxicity monitoring via Chat Interface  

✅ Automatic Discord moderation using AI 

✅ Emoji-based filtering for offensive symbols

✅ Automated actions (warnings, muting, kicking) based on toxicity level

✅ Deployed using Replit + Uptime bot for continuous operation



⚠️ Important Note

This project includes a list of harmful words and phrases strictly for detection and filtering purposes. These words are not intended for offensive use but are necessary for the AI model to function correctly.

🔗 Links for Testing

🌐 Chat Interface: https://ai-harmful-language-frontend.onrender.com/

🤖 Discord Bot Invite: https://discord.gg/qEFhZtf4
