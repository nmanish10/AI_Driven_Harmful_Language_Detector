# AI_Driven_Harmful_Language_Detector
At its core, the system uses the Unary Toxic BERT model, a deep learning-based NLP model specialized in detecting harmful and offensive language. The model processes incoming text and classifies it based on toxicity levels. Actions such as flagging, warning, muting, or kicking users are taken based on the detected toxicity score.
