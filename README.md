# AI_Driven_Harmful_Language_Detector
This project is an AI-powered harmful language detection system that works in two interfaces:

ğŸ”¹ Chat Interface â€“ A web-based chat system where messages are analyzed for toxicity in real-time.

ğŸ”¹ Discord Bot â€“ A bot that moderates Discord servers by detecting and handling harmful messages.

At its core, the system uses the Unary Toxic BERT model, a deep learning-based NLP model specialized in detecting harmful and offensive language. The model processes incoming text and classifies it based on toxicity levels. Actions such as flagging, warning, muting, or kicking users are taken based on the detected toxicity score.


Key Features

âœ… AI-powered text analysis for harmful content

âœ… Chat interface for real-time toxicity monitoring

âœ… Discord bot for automatic moderation

âœ… Emoji-based filtering for offensive symbols

âœ… Automated warnings, muting, and kicking

âœ… Deployed using Replit + Uptime bot




âš ï¸ Important Note
This project includes a list of harmful words and phrases strictly for detection and filtering purposes. These words are not intended for offensive use but are necessary for the AI model to function correctly. Please Ignore.

Link to test Chat Interface : https://ai-harmful-language-frontend.onrender.com/

Link to test Discord Bot : https://discord.gg/qEFhZtf4
