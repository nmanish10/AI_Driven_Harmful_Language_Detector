This project is an AI-powered harmful language detection system that works across two interfaces:

ğŸ”¹ Chat Interface â€“ A web-based chat system where messages are analyzed for toxicity in real-time.

ğŸ”¹ Discord Bot â€“ A bot that moderates Discord servers by detecting and handling harmful messages.

At its core, the system uses the Unary Toxic BERT model, a deep learning-based NLP model specialized in detecting harmful and offensive language. The model processes incoming text and classifies it based on toxicity levels. Actions such as flagging, warning, muting, or kicking users are taken based on the detected toxicity score.

ğŸš€ Key Features
âœ… AI-powered text analysis for harmful content detection

âœ… Real-time toxicity monitoring via Chat Interface  

âœ… Automatic Discord moderation using AI 

âœ… Emoji-based filtering for offensive symbols

âœ… Automated actions (warnings, muting, kicking) based on toxicity level

âœ… Deployed using Replit + Uptime bot for continuous operation



âš ï¸ Important Note

This project includes a list of harmful words and phrases strictly for detection and filtering purposes. These words are not intended for offensive use but are necessary for the AI model to function correctly.

ğŸ”— Links for Testing

ğŸŒ Chat Interface: https://ai-harmful-language-frontend.onrender.com/

ğŸ¤– Discord Bot Invite: https://discord.gg/qEFhZtf4
